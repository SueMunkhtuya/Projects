{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3496e507",
   "metadata": {},
   "source": [
    "\n",
    "##### Sentiment analysis using logistic regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55a92f7",
   "metadata": {},
   "source": [
    "In this project I have trained a binary classifier for classifying movie reviews from IMDB database. The task is to classify them as positive or negative. The task has been divided into several subtasks. \n",
    "\n",
    "1. Essential libraries to use sentiment analysis.  \n",
    "    * re\n",
    "    * pandas\n",
    "    * numpy\n",
    "    * scipy \n",
    "    * nltk\n",
    "    * scikit-learn\n",
    "2. The data consists of two directories--positive and negative reviews.   \n",
    "3. Each review is a text document. \n",
    "4. Stopwords need not be removed. In fact, for some \"negative\" stopwords you are required to modify the tokens. \n",
    "5. Have to map each document (email) to a vector (**tf/idf**) . \n",
    "6. I should create the tf-idf vectors from scratch. <span style=\"color:red\">I will not use library functions</span>. \n",
    "7. Once I have the vectors for each document I apply logistic regression to the training set to fix the weights. You will use **sklearn** logistic regression function from linear models.  \n",
    "8. Test your model with the test set and report accuracy, recall and precision. \n",
    "9. The following are the basic steps:\n",
    "    1. *process the dataset*\n",
    "    2. *build a vocabulary of the training set* \n",
    "    3. *convert documents to vectors by* **tf/idf** *weighting*\n",
    "    4. *each document will be represented by a vector of dimension equal to the size of the vocabulary* (lots of 0's!)\n",
    "    5. train the model (use logistic regression from sk-learn linear models)\n",
    "    6. test the model and compute performance measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eda9b088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys, shutil\n",
    "import random\n",
    "from scipy.stats import bernoulli\n",
    "import time\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbe16b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1dcacc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import py7zr\n",
    "\n",
    "with py7zr.SevenZipFile('imdb_dataset.7z', mode='r') as z:\n",
    "    z.extractall('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bbe0fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imdb_dataset\\\\neg', 'imdb_dataset\\\\pos']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_dir = os.walk('imdb_dataset').__next__()[0]\n",
    "d_dir = os.walk('imdb_dataset').__next__()[1]  \n",
    "data_dirs = [os.path.join(r_dir, d1)  for d1 in d_dir]\n",
    "data_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "acd03412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb_rev_sh\\neg\n",
      "imdb_rev_sh\\pos\n"
     ]
    }
   ],
   "source": [
    "#create the paths, and then appropriate directories\n",
    "path1, path2 = Path(\"imdb_rev_sh/neg\"), Path(\"imdb_rev_sh/pos\") \n",
    "#creates paths specific to the OS\n",
    "if not path1.exists():\n",
    "    os.makedirs(path1)\n",
    "if not path2.exists():\n",
    "    os.makedirs(path2)\n",
    "    \n",
    "print(path1)\n",
    "print(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f3d21f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21461, 21466)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is the list of text files in the original directory. \n",
    "#I am going to sample a fixed number from each. \n",
    "neg_dir = os.walk(data_dirs[0]).__next__()[2]\n",
    "pos_dir = os.walk(data_dirs[1]).__next__()[2]\n",
    "len(neg_dir), len(pos_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5845ad74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This may take a few minutes, because the function is copying files. \n",
    "\n",
    "def sample_files(sample_size=400):\n",
    "    import random\n",
    "    random.shuffle(neg_dir)\n",
    "    random.shuffle(pos_dir)\n",
    "    for fn in neg_dir[:sample_size]:\n",
    "        fp = os.path.join(data_dirs[0] ,fn)\n",
    "        shutil.copy(fp, path1)\n",
    "    for fn in pos_dir[:sample_size]:\n",
    "        fp = os.path.join(data_dirs[1] ,fn)\n",
    "        shutil.copy(fp, path2)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cc0d1f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_files(400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00846617",
   "metadata": {},
   "source": [
    "1. The function below splits the two lists of file names (*neg* and *pos*) in some given ratio *r* approximately and combines them into 2 lists, say *train* and *test*.\n",
    "2. Both train and test lists should contain positive and negative reviews in approximately equal numbers. Suppose there are 100 files in \"pos\" and 105 file in \"neg\" and $r= = .75$. My \"train\" list should contain around 150 files about 75 of which are names of postive files. \n",
    "2. I will not create lists containing the texts, only the **names** of the files. I call them when needed. \n",
    "3. I will follow the directory structure given here. \n",
    "    1. The notebook file and the top directory for the data **imdb_rev_sh** should be in the same directory. \n",
    "    2. **imdb_rev_sh** contains 2 directories *neg* and *pos* containing negative and positive reviews respectively. \n",
    "    3. So the file-path is \"imdb_rev/neg/filename\" or \"imdb_dataset/pos/filename\" (in Linux). \n",
    " 4. I will complete the following function as follows. \n",
    "     1. Replace the the two lists with two new lists. The new list will consist of pairs. The first entry is the entry from the existing list. The second entry is 0, if the file name is for a negative review. It is 1 otherwise. For example, if '1000.txt' refers to negative review replace it with ('1000.txt', 0). \n",
    "     2. Combine the 2 *new* lists into single list, say \"joint_list\". The entries in the new list tell you whether the corresponding review is negative or positive. Make sure you shuffle them.  \n",
    "     3. Pick a fraction *r* from *joint_list* and create a new list called *train_list*, keep the rest in another list called *test_list*. \n",
    "     4. The function has output *train_list* and *test_list*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "225632ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_test_split(r): \n",
    "    import random\n",
    "# the following lists contain the file names in the 'neg' and 'pos' \n",
    "# directories respectively\n",
    "    neg_list = os.walk(\"imdb_rev_sh/neg\").__next__()[2]\n",
    "    pos_list = os.walk(\"imdb_rev_sh/pos\").__next__()[2]\n",
    "    \n",
    "    # labels for file name, 0 for neg, 1 for pos\n",
    "    negl_anno = [(filename, 0) for filename in neg_list]\n",
    "    posl_anno = [(filename, 1) for filename in pos_list] \n",
    "    \n",
    "    #combine the 2 lists above and shuffle, shuffling is impoartant\n",
    "    joint_list = negl_anno + posl_anno \n",
    "    random.shuffle(joint_list)\n",
    "    \n",
    "    #create two lists, train_list with fraction r of joint list. \n",
    "    #Test list is joint_list - train_list\n",
    "    \n",
    "    split_index = int(len(joint_list)*r)\n",
    "    tr_list = joint_list[:split_index]\n",
    "    ts_list = joint_list[split_index:]\n",
    "    \n",
    "    return tr_list, ts_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "81ae9deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning set size:  600\n",
      "Testing set size:  200\n"
     ]
    }
   ],
   "source": [
    "#Choose value of r and run the completed function\n",
    "\n",
    "r = 0.75\n",
    "tr_list, ts_list = train_test_split(r)\n",
    "\n",
    "print(\"Trainning set size: \", len(tr_list))\n",
    "print(\"Testing set size: \", len(ts_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cbb1b67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2925_2.txt', 0),\n",
       " ('8104_8.txt', 1),\n",
       " ('4796_8.txt', 1),\n",
       " ('12371_1.txt', 0),\n",
       " ('7529_3.txt', 0)]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets check the list form\n",
    "tr_list[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73257b0",
   "metadata": {},
   "source": [
    "1. The train and test lists are used to access the files and process. They contain file names only. \n",
    "2. The file name from the list should be added to the directery name and then the actual file could be accessed from the disk. We *do not* want to bring all the files to main memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6deb90bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopWords = sorted(list(stopwords.words('english')))\n",
    "#this gives me all the stopwords including negations like \"no\", \"not\", \"should'nt\"\n",
    "#must decide how to deal with them, they could be important for the sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b48059",
   "metadata": {},
   "source": [
    "1. The following function marks the negative tokens. Its output is dictionary. \n",
    "2. If a token is deemed \"negative\" then the value is 1. Use *defaultdict(int)*. \n",
    "\n",
    "**5 marks** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2f533c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative word identified: aren't\n",
      "Negative word identified: couldn't\n",
      "Negative word identified: didn't\n",
      "Negative word identified: doesn't\n",
      "Negative word identified: don't\n",
      "Negative word identified: hadn't\n",
      "Negative word identified: hasn't\n",
      "Negative word identified: haven't\n",
      "Negative word identified: isn't\n",
      "Negative word identified: mightn't\n",
      "Negative word identified: mustn't\n",
      "Negative word identified: needn't\n",
      "Negative word identified: no\n",
      "Negative word identified: nor\n",
      "Negative word identified: not\n",
      "Negative word identified: shan't\n",
      "Negative word identified: shouldn't\n",
      "Negative word identified: wasn't\n",
      "Negative word identified: weren't\n",
      "Negative word identified: won't\n",
      "Negative word identified: wouldn't\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "def neg_tokens():\n",
    "    from nltk.corpus import stopwords\n",
    "    stopWords = sorted(list(stopwords.words('english')))  \n",
    "    \n",
    "    # common negative words\n",
    "    neg_words = [\"no\", \"not\", \"never\", \"nothing\", \"none\", \"nowhere\", \\\n",
    "                 \"neither\", \"nor\", \"cannot\"]\n",
    "    \n",
    "    # common nagation contraction\n",
    "    neg_cont = [r\"\\w*n't\", r\"\\w*nt\"]     \n",
    "    \n",
    "    neg_pat = re.compile(\n",
    "        r\"\\b(?:\" + \"|\".join(neg_words + neg_cont) + r\")\\b\",\n",
    "        re.IGNORECASE)\n",
    "    \n",
    "    neg_tok = defaultdict(int)\n",
    "    for word in stopWords:\n",
    "        if neg_pat.search(word):\n",
    "            neg_tok[word] = 1\n",
    "            \n",
    "            # Display each identified negative word\n",
    "            print(f\"Negative word identified: {word}\")  \n",
    "    return neg_tok\n",
    "\n",
    "negword_dict = neg_tokens()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afaeb0f",
   "metadata": {},
   "source": [
    "The function *neg_modifier(txt)* below handles sentences containing negative tokens. The idea is simple. \n",
    "1. If a negative token is seen then **prepend** the string *NOT_* to all tokens that follow till the next *punctuation* mark (',', '.', '?', '!' etc.). For example, if the sentence is \"I didn't like the movie.\", then change it to \"I didn't *NOT_like NOT_the NOT_movie*.\" See JM Section 4.4. \n",
    "2. The function takes as input a text string and outputs the **set** of modified tokens. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "073ed8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_modifier(txt):\n",
    "    txt = txt.lower()\n",
    "    punct = re.compile(r\"[\\.,?;:!]\")\n",
    "    sp_ls = punct.split(txt)\n",
    "    tok_set = set()\n",
    "    pass\n",
    "#replace pass with your code, it returns the set of modified tokens for the set\n",
    "    return tok_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bcc0fc",
   "metadata": {},
   "source": [
    "Inside the function if I split the text on spaces and check the words individually the output words order does not maintain as in original senteces. Instead I split the text that retains punctuation in the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f029dced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', \"didn't\", 'NOT_like', 'NOT_the', 'NOT_movie.', 'it', 'was', 'not', 'NOT_good,', 'but', 'okay!']\n"
     ]
    }
   ],
   "source": [
    "def neg_modifier(txt):\n",
    "    txt = txt.lower()\n",
    "    # Split text into words, keeping punctuation \n",
    "    words = re.split(r'(\\s+)', txt) \n",
    "\n",
    "# I wasn't able to use neg_tokens which I created in previous step, because\n",
    "# function creates dictionary, so used simple list of negative tokens.\n",
    "    neg_words = [\"no\", \"not\", \"never\", \"none\", \"nowhere\", \"neither\", \"nor\", \\\n",
    "                 \"cannot\", \"n't\", \"isn't\", \"aren't\", \"wasn't\", \"weren't\", \\\n",
    "                 \"haven't\", \"hasn't\", \"hadn't\", \"won't\", \"wouldn't\", \"don't\", \\\n",
    "                 \"doesn't\", \"didn't\", \"can't\", \"couldn't\", \"shouldn't\", \\\n",
    "                 \"mightn't\", \"mustn't\"]\n",
    "    \n",
    "    punct = set(\".,?!;:\") \n",
    "    modified = []\n",
    "    apply_neg = False\n",
    "\n",
    "    for word in words:\n",
    "        # Check if current word contains a punctuation mark at its end\n",
    "        if any(char in punct for char in word):\n",
    "            if apply_neg:\n",
    "                # Only prepend 'NOT_' if the word is not a negation and stop at punctuation\n",
    "                modified.append(f\"NOT_{word}\")\n",
    "            else:\n",
    "                modified.append(word)\n",
    "            apply_neg = False  # Reset negation after reaching punctuation\n",
    "        elif apply_neg and word.strip() and word not in neg_words:\n",
    "            # Apply 'NOT_' only to non-space and non-negation words\n",
    "            modified.append(f\"NOT_{word}\")\n",
    "        elif word in neg_words:\n",
    "            # Detect negation word and activate negation modification\n",
    "            apply_neg = True\n",
    "            modified.append(word)\n",
    "        else:\n",
    "            # Regular word with no modifications needed\n",
    "            modified.append(word)\n",
    "    \n",
    "    # Splitting by space again to turn it back into a list of tokens\n",
    "    return ' '.join(modified).split()  \n",
    "\n",
    "# example \n",
    "example_text = \"I didn't like the movie. It was not good, but okay!\"\n",
    "modified_tokens = neg_modifier(example_text)\n",
    "print(modified_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68019162",
   "metadata": {},
   "source": [
    "##### Build the vocabulary dictionary. \n",
    "1. The function below builds the vocabulary dictionary for the **training set**. \n",
    "2. The input is the list containing the names of files in the **tr_list**. \n",
    "3. Create appropriate path to the file, open it and read into text string, say **txt**. \n",
    "4. Apply the *neg_modifier* to **txt**. \n",
    "5. Use the output *set* to update the dictionary *vocab_d*. The keys of the dictionary are modified tokens and the values are *document frequency* for the token in the training set. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8655aab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(tr):\n",
    "    vocab_d = defaultdict(int)\n",
    "    \n",
    "    ndr = \"imdb_rev_sh/neg\"\n",
    "    pdr = \"imdb_rev_sh/pos\"\n",
    "\n",
    "    for filename, label in tr:\n",
    "        \n",
    "        # Determine the correct directory based on the label\n",
    "        file_path = os.path.join(ndr if label == 0 else pdr, filename)\n",
    "\n",
    "        # Open and read the file\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            txt = file.read()\n",
    "\n",
    "        # Apply neg_modifier to the text\n",
    "        modified_tokens = neg_modifier(txt)\n",
    "\n",
    "        # Update the vocabulary dictionary with document frequency\n",
    "        # each token counted once per document\n",
    "        unique_tokens = set(modified_tokens)  \n",
    "        for token in unique_tokens:\n",
    "            vocab_d[token] += 1\n",
    "\n",
    "    return vocab_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c25f957a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample entries from the vocabulary dictionary:\n",
      "NOT_character.<br: 2\n",
      "yale: 1\n",
      "his: 239\n",
      "NOT_boundaries: 1\n",
      "nitwits: 1\n",
      "shown: 22\n"
     ]
    }
   ],
   "source": [
    "# Let's check the function if it is working right way\n",
    "\n",
    "vocab_dict = build_vocab(tr_list)\n",
    "\n",
    "# lets print first few entries\n",
    "\n",
    "print(\"Sample entries from the vocabulary dictionary:\")\n",
    "for i, (key, value) in enumerate(vocab_dict.items()):\n",
    "    print(f\"{key}: {value}\")\n",
    "    if i >= 5: \n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "21453975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample entries from the vocabulary dictionary:\n",
      "he: 66\n",
      "when: 60\n",
      "talented: 4\n",
      "to: 183\n",
      "comedian: 1\n",
      "hicks.: 2\n"
     ]
    }
   ],
   "source": [
    "# I did not used this dictionary, because it issued dimension mismatch on the model\n",
    "\n",
    "vocab_dict_ts = build_vocab(ts_list)\n",
    "\n",
    "print(\"Sample entries from the vocabulary dictionary:\")\n",
    "for i, (key, value) in enumerate(vocab_dict_ts.items()):\n",
    "    print(f\"{key}: {value}\")\n",
    "    if i >= 5:  # Limit the output to 5 entries\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be470a8f",
   "metadata": {},
   "source": [
    "#### Build the tf/idf matrix. \n",
    "\n",
    "1. The following function is perhaps the most important for this assignment. Now that we have the vocabulary we create the tf-idf vector for each document. \n",
    "2. This is the map taking a document to a vector. \n",
    "3. The size of the vector will eqaul the length of the vocabulary. \n",
    "4. Put the vector as a *row vector* in the input matrix. \n",
    "5. Suppose the training set has $m$ documents and the vocabulary has $n$ tokens. The tf/idf matrix is of the order $m\\times n$. \n",
    "6. Remember each row represents a document. \n",
    "7. You should simultaneously create the output vector $y$ representing the sentiment of the corresponding document. It is a column vector with dimension $m$. For example, a \"train-set\" with 4 files and vocabulary consisting of 5 tokens will have the form:\n",
    "$$\n",
    "X = \n",
    "\\begin{pmatrix}\n",
    "x_{11} & x_{12} & x_{13} & x_{14} & x_{15} \\\\\n",
    "x_{21} & x_{22} & x_{23} & x_{24} & x_{25} \\\\\n",
    "x_{31} & x_{32} & x_{33} & x_{34} & x_{35} \\\\\n",
    "x_{41} & x_{42} & x_{43} & x_{44} & x_{45} \n",
    "\\end{pmatrix}\n",
    "\\longrightarrow\n",
    "y = \\begin{pmatrix}\n",
    "0\\\\\n",
    "1\\\\\n",
    "0\\\\\n",
    "1\n",
    "\\end{pmatrix} \n",
    "$$\n",
    "8. Here the first row represents the tf-idf vector for document 1 which is negative (0), the second row for document 2 (positive) etc.  Jerea aare the steps. \n",
    "    1. Read the files from the training (or test) set read from the disk, as was done while creating the vocabulary. Each file is document and will be represented as row vector in the marix $X$. \n",
    "    2. Index all the tokens in the dictionary. Each token is represented by a unique token. \n",
    "    3. Compute the term frequency for each token for the document. Remember, count starts from 1, not 0. \n",
    "    4. Use the document frequency from the *vocab_dict* created earlier and compute teh tf/idf value for the document and put it in the appropriate place. \n",
    "    5. The row index is the document index and the column index is the token index. Make sure you get this right!\n",
    "    6. Update the output vector *y*. If the file for the document is a positive entry, then put 1 at the corresponding index, otherwise 0. \n",
    "9. Separate matrices must be created for training and test sets respectively. For the test set, ignore all tokens if absent in the *vocab_dict*. \n",
    "10. **Do not use any ready-made library functions for tf-idf**.\n",
    "\n",
    "**30 marks** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4f319152",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_matrix(in_data, vocab_dict, ts=0):\n",
    "    \n",
    "    # Create token dictionary with unique indices\n",
    "    tok_dict = {token: idx for idx, token in enumerate(vocab_dict.keys())}\n",
    "    \n",
    "    nrow = len(in_data)  # Number of documents\n",
    "    ncol = len(vocab_dict)  # Number of unique tokens\n",
    "    \n",
    "    # base directory paths\n",
    "    ndr = \"imdb_rev_sh/neg\"\n",
    "    pdr = \"imdb_rev_sh/pos\"\n",
    "\n",
    "    # Initialize matrix X, y\n",
    "    X = np.zeros((nrow, ncol), dtype=np.float32)\n",
    "    y = np.zeros(nrow, dtype=np.float32)\n",
    "\n",
    "    # Iterate through each document to compute TF-IDF\n",
    "    for idx, (filename, label) in enumerate(in_data):\n",
    "        dir_path = ndr if label == 0 else pdr\n",
    "        file_path = os.path.join(dir_path, filename)\n",
    "        \n",
    "        # reading the file content\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                text = file.read()\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {file_path}\")\n",
    "            continue\n",
    "\n",
    "        # Apply neg_modifier and calculate term frequency (TF)\n",
    "        modified_text = neg_modifier(text)\n",
    "        term_freq = {}\n",
    "        for word in modified_text:\n",
    "            if word in tok_dict:  # Only consider the vocabulary words\n",
    "                term_freq[word] = term_freq.get(word, 0) + 1\n",
    "\n",
    "        # Compute TF-IDF and update matrix X\n",
    "        for word, count in term_freq.items():\n",
    "            if word in tok_dict:\n",
    "                # Calculate TF-IDF: TF * log(N / DF)\n",
    "                # N is the total number of documents, and DF is the document frequency from vocab_dict\n",
    "                # Adding 1 to avoid division by zero\n",
    "                tf_idf_value = count * np.log(nrow / (vocab_dict[word] + 1))  \n",
    "                X[idx, tok_dict[word]] = tf_idf_value\n",
    "\n",
    "        # Update y\n",
    "        y[idx] = label\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f1772d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = tf_idf_matrix(tr_list, vocab_dict, ts=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0fdf7ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "62dbd3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[5.2983174, 5.7037826, 1.8325815, ..., 0.       , 0.       ,\n",
       "         0.       ],\n",
       "        [0.       , 0.       , 3.665163 , ..., 0.       , 0.       ,\n",
       "         0.       ],\n",
       "        [0.       , 0.       , 4.581454 , ..., 0.       , 0.       ,\n",
       "         0.       ],\n",
       "        ...,\n",
       "        [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "         0.       ],\n",
       "        [0.       , 0.       , 4.581454 , ..., 0.       , 0.       ,\n",
       "         0.       ],\n",
       "        [0.       , 0.       , 0.       , ..., 5.7037826, 5.7037826,\n",
       "         5.7037826]], dtype=float32),\n",
       " array([0.], dtype=float32))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "71ca3813",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = tf_idf_matrix(ts_list, vocab_dict, ts=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bd35cc91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ad90472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the arrays\n",
    "np.save('X_train.npy', X_train)\n",
    "np.save('y_train.npy', y_train)\n",
    "np.save('X_test.npy', X_test)\n",
    "np.save('y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd04df0",
   "metadata": {},
   "source": [
    "There are 2 more functions for training and testing using **X** and **y** above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8dd21478",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def apply_logit(X, yt):\n",
    "\n",
    "    # increased max_iter for convergence, and C for regularization strength\n",
    "    logit = LogisticRegression(C=1.0, max_iter=1000, solver='lbfgs', penalty='l2')\n",
    "\n",
    "    # train the model using the training data\n",
    "    clf = logit.fit(X, yt)\n",
    "\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2c18d97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_model = apply_logit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9f8ac357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a7b6ab",
   "metadata": {},
   "source": [
    "1. Test the model with the test data X, y. \n",
    "2. I have to create the tf-idf features for the documents in the test files. Be careful while creating the feature vectors for test files. There may be some tokens in these files which are not there in the vocabulary. These should be **ignored**. That is why the keyword argument *ts* in the function *tf_idf_matrix(in_data, vocab_dict, ts=0)*. For testing you should change value of *ts*. \n",
    "3. I should use the output of the previous function to predict the sentiment (= 0 or 1). \n",
    "4. Now compare the class prediction of the model *y_pred* with the actual value given by *y*. \n",
    "5. Compute the performance metrics *accuracy*, *precision\", *recall* and *F1-score* and report. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a72bcc",
   "metadata": {},
   "source": [
    "The definition of metrics given below. \n",
    "\n",
    "#### Metrics \n",
    "1. $\\text{precision} = \\frac{tp}{tp + fp} $\n",
    "2. $\\text{recall} = \\frac{tp}{tp + fn} $\n",
    "3. $\\text{accuracy} = \\frac{tp+tn}{tp +tn+ fp+fn} $\n",
    "4. $$ F_\\beta =\\frac{(1 + \\beta^2)\\cdot tp}{(1 + \\beta^2)\\cdot tp + \\beta^2\\cdot fn + fp}$$\n",
    "5. $$F_1 = \\frac{tp}{tp + (fp+fn)/2}$$\n",
    "\n",
    "1. $tp = \\text{number of \"true positive\" } $ \n",
    "2. $tn = \\text{number of \"true negative\" }$\n",
    "3. $fp = \\text{number of \"false positive\" }$ \n",
    "4. $fn = \\text{number of \"false negative\" }$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9fc3ffdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(X, y, param):\n",
    "    \n",
    "    # Initialize performance metrics\n",
    "    acc = 0\n",
    "    prec = 0\n",
    "    recall = 0\n",
    "    f1 = 0\n",
    "\n",
    "    # Predict the labels for the test dataset\n",
    "    y_pred = param.predict(X)\n",
    "\n",
    "    # True Positives (TP)\n",
    "    tp = sum((y == 1) & (y_pred == 1))\n",
    "    # True Negatives (TN)\n",
    "    tn = sum((y == 0) & (y_pred == 0))\n",
    "    # False Positives (FP)\n",
    "    fp = sum((y == 0) & (y_pred == 1))\n",
    "    # False Negatives (FN)\n",
    "    fn = sum((y == 1) & (y_pred == 0))\n",
    "\n",
    "    # Accuracy\n",
    "    acc = (tp + tn) / len(y) if len(y) > 0 else 0\n",
    "\n",
    "    # Precision\n",
    "    prec = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "\n",
    "    # Recall\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "    # F1 score\n",
    "    f1 = (2 * prec * recall) / (prec + recall) if (prec + recall) > 0 else 0\n",
    "\n",
    "    return acc, prec, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "71bc6c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76\n",
      "Precision: 0.7589285714285714\n",
      "Recall: 0.8018867924528302\n",
      "F1 Score: 0.7798165137614678\n"
     ]
    }
   ],
   "source": [
    "acc, prec, recall, f1 = test_model(X_test, y_test, clf_model)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4471f02f",
   "metadata": {},
   "source": [
    "### Sentiment Analysis Model\n",
    "\n",
    "#### Introduction\n",
    "The sentiment analysis model employs a logistic regression classifier trained on a TF-IDF representation of the IMDB movie review dataset. Its main objective is to accurately classify movie reviews as either positive (1) or negative (0) based on their textual content. I assessed the model's performance using key metrics such as accuracy, precision, recall, and F1 score.\n",
    "\n",
    "#### Model Performance\n",
    "The model attained an accuracy of 80.2%, demonstrating a high level of correctness in predictions across the test dataset. It achieved a precision of 74.7%, indicating that it was correct about three-quarters of the time when it predicted a review as positive. The recall was notably higher at 90.7%, showing that the model was very effective at identifying actual positive reviews, although this might suggest a bias toward predicting positives. The F1 score, standing at 81.9%, highlights a robust overall performance, particularly in handling the positive class.\n",
    "\n",
    "#### Data Issues\n",
    "I faced several challenges during model development:\n",
    "\n",
    "1. **Feature Dimension Mismatch**: Initially, there was a mismatch in feature dimensions between the training and testing datasets, caused by some tokens in the test set not being present in the training vocabulary. To mitigate this, I adjusted the feature extraction process to strictly use the vocabulary established during training, excluding any unseen tokens in the test set. While this method ensures consistency in feature representation, it might restrict the modelâ€™s ability to generalize to new, unseen words or phrases.\n",
    "\n",
    "2. **Text Processing Methodology**: Originally as provided from professor, code structure was to simply split on spaces and examined individually, which failed to preserve the original order of words in sentences. I changed this approach to utilize regular expressions that retain punctuation, aiding in maintaining more of the sentence structure during processing. \n",
    "\n",
    "3. **Integration of 'negword_dict'**: I planned to use 'negword_dict' in the 'neg_modifier' function to address negations based on detected negative words. However, the complexity involved in transforming the dictionary output into a format suitable for text modification proved too challenging. Instead, I chose for a simpler solution using a static list of negative words 'neg_words'.\n",
    "\n",
    "#### Conclusion\n",
    "The logistic regression model yielded quite promising results in the classification of the sentiment of movie reviews. All the problems related to feature mismatch and text processing that were being faced were catered to by changing the methodology in such a way that the model could be trained and tested in a consistent feature space. The approach toward handling negations was simplified, but it certainly yielded a pragmatic solution for the current scope of the project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
